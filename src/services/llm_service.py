"""
Handles LLM query-response generation
"""

def generate_llm_response(query: str, context_chunks: list[dict]) -> str:
    """
    Generates a conversational reply using context.
    """
    # TODO: connect to Gemini or other LLM later
    return "Mock AI response based on context."
